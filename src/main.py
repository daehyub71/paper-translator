"""
Paper Translator CLI
ArXiv ë…¼ë¬¸ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤
"""
import sys
import json
from pathlib import Path
from typing import Optional
from datetime import datetime

import typer
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
from rich.syntax import Syntax
from rich import print as rprint

from src.graph import run_translation, translate_arxiv
from src.state import get_state_summary
from src.db.repositories import TerminologyRepository
from src.feedback import (
    SyncManager,
    SyncResult,
    SyncItem,
    SyncAction,
    get_changed_files,
)
from src.collectors import (
    ArxivCollector,
    SemanticScholarCollector,
    ArxivPaper,
    SemanticScholarPaper,
    RateLimitError,
)

# ì½˜ì†” ë° ì•± ì´ˆê¸°í™”
console = Console()
app = typer.Typer(
    name="paper-translator",
    help="ArXiv ë…¼ë¬¸ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ë„êµ¬",
    add_completion=False,
    rich_markup_mode="rich",
)

# í•˜ìœ„ ëª…ë ¹ì–´ ê·¸ë£¹
terms_app = typer.Typer(
    name="terms",
    help="ì „ë¬¸ìš©ì–´ ê´€ë¦¬",
    add_completion=False,
)
app.add_typer(terms_app, name="terms")


# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ===

def print_header(title: str):
    """í—¤ë” ì¶œë ¥"""
    console.print(Panel(f"[bold blue]{title}[/bold blue]", expand=False))


def print_success(message: str):
    """ì„±ê³µ ë©”ì‹œì§€ ì¶œë ¥"""
    console.print(f"[green]âœ“[/green] {message}")


def print_error(message: str):
    """ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥"""
    console.print(f"[red]âœ—[/red] {message}")


def print_warning(message: str):
    """ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥"""
    console.print(f"[yellow]![/yellow] {message}")


def print_info(message: str):
    """ì •ë³´ ë©”ì‹œì§€ ì¶œë ¥"""
    console.print(f"[blue]â„¹[/blue] {message}")


def create_stats_table(stats: dict) -> Table:
    """í†µê³„ í…Œì´ë¸” ìƒì„±"""
    table = Table(title="ë²ˆì—­ í†µê³„", show_header=True, header_style="bold magenta")
    table.add_column("í•­ëª©", style="cyan")
    table.add_column("ê°’", style="green")

    table.add_row("ì´ ì²­í¬", str(stats.get("total_chunks", "N/A")))
    table.add_row("ì™„ë£Œ", str(stats.get("completed_chunks", "N/A")))
    table.add_row("ì‹¤íŒ¨", str(stats.get("failed_chunks", "N/A")))
    table.add_row("ì´ í† í°", f"{stats.get('total_tokens', 0):,}")
    table.add_row("ì†Œìš” ì‹œê°„", f"{stats.get('total_time_sec', 0):.1f}ì´ˆ")
    table.add_row("ì˜ˆìƒ ë¹„ìš©", stats.get("estimated_cost_usd", "N/A"))
    table.add_row("ìš©ì–´ ë§¤ì¹­ë¥ ", stats.get("term_match_rate", "N/A"))

    return table


# === translate ëª…ë ¹ì–´ ===

@app.command("translate", help="ë…¼ë¬¸ ë²ˆì—­")
def translate(
    url: Optional[str] = typer.Option(
        None, "--url", "-u",
        help="ArXiv PDF URL"
    ),
    arxiv_id: Optional[str] = typer.Option(
        None, "--arxiv-id", "-a",
        help="ArXiv ë…¼ë¬¸ ID (ì˜ˆ: 1706.03762)"
    ),
    file: Optional[Path] = typer.Option(
        None, "--file", "-f",
        help="ë¡œì»¬ PDF íŒŒì¼ ê²½ë¡œ",
        exists=True,
        file_okay=True,
        dir_okay=False,
        readable=True,
    ),
    domain: str = typer.Option(
        "General", "--domain", "-d",
        help="ë…¼ë¬¸ ë„ë©”ì¸ (NLP, CV, RL, General)"
    ),
    output_dir: Optional[Path] = typer.Option(
        None, "--output", "-o",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ./output)"
    ),
    no_references: bool = typer.Option(
        True, "--no-references/--with-references",
        help="References ì„¹ì…˜ ì œì™¸ ì—¬ë¶€"
    ),
    no_tables: bool = typer.Option(
        False, "--no-tables/--with-tables",
        help="í‘œ ì¶”ì¶œ ì œì™¸ ì—¬ë¶€"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run",
        help="ì‹¤ì œ ë²ˆì—­ ì—†ì´ ì˜ˆìƒ ë¹„ìš©ë§Œ ê³„ì‚°"
    ),
    verbose: bool = typer.Option(
        False, "--verbose", "-v",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥"
    ),
):
    """
    ArXiv ë…¼ë¬¸ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        # ArXiv IDë¡œ ë²ˆì—­
        paper-translator translate --arxiv-id 1706.03762 --domain NLP

        # URLë¡œ ë²ˆì—­
        paper-translator translate --url https://arxiv.org/pdf/1706.03762

        # ë¡œì»¬ PDF ë²ˆì—­
        paper-translator translate --file ./paper.pdf --domain CV
    """
    # ì…ë ¥ ê²€ì¦
    source = None
    if arxiv_id:
        source = arxiv_id
        print_info(f"ArXiv ID: {arxiv_id}")
    elif url:
        source = url
        print_info(f"URL: {url}")
    elif file:
        source = str(file)
        print_info(f"íŒŒì¼: {file}")
    else:
        print_error("--url, --arxiv-id, ë˜ëŠ” --file ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        raise typer.Exit(1)

    print_header("Paper Translator")
    console.print(f"ë„ë©”ì¸: [cyan]{domain}[/cyan]")
    console.print(f"References ì œì™¸: [cyan]{no_references}[/cyan]")
    console.print(f"í‘œ ì¶”ì¶œ: [cyan]{not no_tables}[/cyan]")
    console.print()

    # Dry run ëª¨ë“œ
    if dry_run:
        print_warning("Dry run ëª¨ë“œ: ì‹¤ì œ ë²ˆì—­ì€ ìˆ˜í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        # TODO: ì˜ˆìƒ ë¹„ìš© ê³„ì‚° ë¡œì§
        console.print("[dim]ì˜ˆìƒ ë¹„ìš© ê³„ì‚° ê¸°ëŠ¥ì€ ì¶”í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.[/dim]")
        return

    # ë²ˆì—­ ì‹¤í–‰
    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console,
        ) as progress:
            task = progress.add_task("[cyan]ë²ˆì—­ ì¤‘...", total=8)

            # ì§„í–‰ ìƒí™© ì½œë°±
            node_progress = {
                "fetch_pdf": 1,
                "parse_pdf": 2,
                "chunk_text": 3,
                "pre_process": 4,
                "translate_chunks": 5,
                "post_process": 6,
                "generate_markdown": 7,
                "save_output": 8,
            }

            def progress_callback(node_name: str, status: str):
                if node_name in node_progress:
                    progress.update(task, completed=node_progress[node_name])
                    progress.update(task, description=f"[cyan]{node_name}...")

            # ë²ˆì—­ ì‹¤í–‰
            final_state = run_translation(
                source=source,
                domain=domain,
                exclude_references=no_references,
                extract_tables=not no_tables,
                progress_callback=progress_callback,
            )

        console.print()

        # ê²°ê³¼ ì¶œë ¥
        if final_state.get("status") == "failed":
            print_error(f"ë²ˆì—­ ì‹¤íŒ¨: {final_state.get('error')}")
            raise typer.Exit(1)

        # ì„±ê³µ
        output_info = final_state.get("output", {})
        stats = final_state.get("stats", {})
        metadata = final_state.get("metadata", {})

        print_success("ë²ˆì—­ ì™„ë£Œ!")
        console.print()

        # ë©”íƒ€ë°ì´í„°
        console.print(f"[bold]ì œëª©:[/bold] {metadata.get('title', 'N/A')}")
        if metadata.get("arxiv_id"):
            console.print(f"[bold]ArXiv:[/bold] {metadata.get('arxiv_id')}")
        console.print()

        # í†µê³„ í…Œì´ë¸”
        console.print(create_stats_table(stats))
        console.print()

        # ì¶œë ¥ íŒŒì¼
        file_path = output_info.get("file_path", "N/A")
        console.print(f"[bold]ì¶œë ¥ íŒŒì¼:[/bold] [green]{file_path}[/green]")
        console.print(f"[bold]MD5 í•´ì‹œ:[/bold] {output_info.get('md5_hash', 'N/A')}")

    except KeyboardInterrupt:
        print_warning("\në²ˆì—­ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        raise typer.Exit(130)
    except Exception as e:
        print_error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        if verbose:
            console.print_exception()
        raise typer.Exit(1)


# === terms ëª…ë ¹ì–´ ê·¸ë£¹ ===

@terms_app.command("list", help="ì „ë¬¸ìš©ì–´ ëª©ë¡ ì¡°íšŒ")
def terms_list(
    domain: Optional[str] = typer.Option(
        None, "--domain", "-d",
        help="ë„ë©”ì¸ í•„í„° (NLP, CV, RL, General)"
    ),
    search: Optional[str] = typer.Option(
        None, "--search", "-s",
        help="ê²€ìƒ‰ì–´"
    ),
    limit: int = typer.Option(
        50, "--limit", "-n",
        help="ìµœëŒ€ ì¶œë ¥ ê°œìˆ˜"
    ),
    json_output: bool = typer.Option(
        False, "--json",
        help="JSON í˜•ì‹ ì¶œë ¥"
    ),
):
    """
    ë“±ë¡ëœ ì „ë¬¸ìš©ì–´ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        # ì „ì²´ ëª©ë¡
        paper-translator terms list

        # NLP ë„ë©”ì¸ë§Œ
        paper-translator terms list --domain NLP

        # ê²€ìƒ‰
        paper-translator terms list --search attention
    """
    try:
        terms = TerminologyRepository.get_all(domain=domain, limit=limit)

        # ê²€ìƒ‰ì–´ í•„í„°
        if search:
            search_lower = search.lower()
            terms = [
                t for t in terms
                if search_lower in t.get("source_text", "").lower()
                or search_lower in t.get("target_text", "").lower()
            ]

        if json_output:
            console.print_json(data=terms)
            return

        # í…Œì´ë¸” ì¶œë ¥
        table = Table(title=f"ì „ë¬¸ìš©ì–´ ëª©ë¡ ({len(terms)}ê°œ)", show_header=True, header_style="bold cyan")
        table.add_column("ID", style="dim", width=8)
        table.add_column("ì›ë¬¸ (Source)", style="cyan")
        table.add_column("ë²ˆì—­ (Target)", style="green")
        table.add_column("ë„ë©”ì¸", style="yellow")
        table.add_column("ì‚¬ìš©íšŸìˆ˜", justify="right")

        for term in terms:
            table.add_row(
                str(term.get("id", ""))[:8],
                term.get("source_text", ""),
                term.get("target_text", ""),
                term.get("domain", ""),
                str(term.get("usage_count", 0)),
            )

        console.print(table)

    except Exception as e:
        print_error(f"ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise typer.Exit(1)


@terms_app.command("add", help="ì „ë¬¸ìš©ì–´ ì¶”ê°€")
def terms_add(
    source: str = typer.Option(
        ..., "--source", "-s",
        help="ì›ë¬¸ (ì˜ì–´)"
    ),
    target: str = typer.Option(
        ..., "--target", "-t",
        help="ë²ˆì—­ì–´ (í•œêµ­ì–´)"
    ),
    domain: str = typer.Option(
        "General", "--domain", "-d",
        help="ë„ë©”ì¸ (NLP, CV, RL, General)"
    ),
    description: Optional[str] = typer.Option(
        None, "--description",
        help="ì„¤ëª…"
    ),
):
    """
    ìƒˆ ì „ë¬¸ìš©ì–´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        paper-translator terms add --source "attention" --target "ì–´í…ì…˜" --domain NLP
    """
    try:
        term_data = {
            "source_text": source,
            "target_text": target,
            "domain": domain,
            "description": description or "",
            "usage_count": 0,
        }

        result = TerminologyRepository.create(term_data)

        if result:
            print_success(f"ìš©ì–´ ì¶”ê°€ ì™„ë£Œ: '{source}' â†’ '{target}'")
            console.print(f"  ë„ë©”ì¸: {domain}")
            if description:
                console.print(f"  ì„¤ëª…: {description}")
        else:
            print_error("ìš©ì–´ ì¶”ê°€ ì‹¤íŒ¨")
            raise typer.Exit(1)

    except Exception as e:
        print_error(f"ì¶”ê°€ ì‹¤íŒ¨: {e}")
        raise typer.Exit(1)


@terms_app.command("update", help="ì „ë¬¸ìš©ì–´ ìˆ˜ì •")
def terms_update(
    term_id: str = typer.Argument(
        ...,
        help="ìˆ˜ì •í•  ìš©ì–´ ID"
    ),
    source: Optional[str] = typer.Option(
        None, "--source", "-s",
        help="ìƒˆ ì›ë¬¸"
    ),
    target: Optional[str] = typer.Option(
        None, "--target", "-t",
        help="ìƒˆ ë²ˆì—­ì–´"
    ),
    domain: Optional[str] = typer.Option(
        None, "--domain", "-d",
        help="ìƒˆ ë„ë©”ì¸"
    ),
    description: Optional[str] = typer.Option(
        None, "--description",
        help="ìƒˆ ì„¤ëª…"
    ),
):
    """
    ê¸°ì¡´ ì „ë¬¸ìš©ì–´ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        paper-translator terms update abc123 --target "ìƒˆë²ˆì—­ì–´"
    """
    try:
        update_data = {}
        if source:
            update_data["source_text"] = source
        if target:
            update_data["target_text"] = target
        if domain:
            update_data["domain"] = domain
        if description is not None:
            update_data["description"] = description

        if not update_data:
            print_warning("ìˆ˜ì •í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        result = TerminologyRepository.update(term_id, update_data)

        if result:
            print_success(f"ìš©ì–´ ìˆ˜ì • ì™„ë£Œ: {term_id}")
            for key, value in update_data.items():
                console.print(f"  {key}: {value}")
        else:
            print_error("ìš©ì–´ ìˆ˜ì • ì‹¤íŒ¨ (IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ)")
            raise typer.Exit(1)

    except Exception as e:
        print_error(f"ìˆ˜ì • ì‹¤íŒ¨: {e}")
        raise typer.Exit(1)


@terms_app.command("delete", help="ì „ë¬¸ìš©ì–´ ì‚­ì œ")
def terms_delete(
    term_id: str = typer.Argument(
        ...,
        help="ì‚­ì œí•  ìš©ì–´ ID"
    ),
    force: bool = typer.Option(
        False, "--force", "-f",
        help="í™•ì¸ ì—†ì´ ì‚­ì œ"
    ),
):
    """
    ì „ë¬¸ìš©ì–´ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        paper-translator terms delete abc123
        paper-translator terms delete abc123 --force
    """
    try:
        if not force:
            confirm = typer.confirm(f"ì •ë§ '{term_id}' ìš©ì–´ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            if not confirm:
                print_info("ì‚­ì œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return

        result = TerminologyRepository.delete(term_id)

        if result:
            print_success(f"ìš©ì–´ ì‚­ì œ ì™„ë£Œ: {term_id}")
        else:
            print_error("ìš©ì–´ ì‚­ì œ ì‹¤íŒ¨ (IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ)")
            raise typer.Exit(1)

    except Exception as e:
        print_error(f"ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise typer.Exit(1)


@terms_app.command("export", help="ì „ë¬¸ìš©ì–´ ë‚´ë³´ë‚´ê¸°")
def terms_export(
    output: Path = typer.Option(
        Path("./terminology_export.json"), "--output", "-o",
        help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ"
    ),
    domain: Optional[str] = typer.Option(
        None, "--domain", "-d",
        help="ë„ë©”ì¸ í•„í„°"
    ),
    format: str = typer.Option(
        "json", "--format", "-f",
        help="ì¶œë ¥ í˜•ì‹ (json, csv)"
    ),
):
    """
    ì „ë¬¸ìš©ì–´ë¥¼ íŒŒì¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        paper-translator terms export --output terms.json
        paper-translator terms export --domain NLP --format csv
    """
    try:
        terms = TerminologyRepository.get_all(domain=domain, limit=10000)

        if format == "json":
            with open(output, "w", encoding="utf-8") as f:
                json.dump(terms, f, ensure_ascii=False, indent=2)
        elif format == "csv":
            import csv
            with open(output, "w", encoding="utf-8", newline="") as f:
                if terms:
                    writer = csv.DictWriter(f, fieldnames=terms[0].keys())
                    writer.writeheader()
                    writer.writerows(terms)
        else:
            print_error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")
            raise typer.Exit(1)

        print_success(f"ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output} ({len(terms)}ê°œ ìš©ì–´)")

    except Exception as e:
        print_error(f"ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        raise typer.Exit(1)


@terms_app.command("import", help="ì „ë¬¸ìš©ì–´ ê°€ì ¸ì˜¤ê¸°")
def terms_import(
    file: Path = typer.Argument(
        ...,
        help="ê°€ì ¸ì˜¬ íŒŒì¼ ê²½ë¡œ",
        exists=True,
        file_okay=True,
        readable=True,
    ),
    overwrite: bool = typer.Option(
        False, "--overwrite",
        help="ê¸°ì¡´ ìš©ì–´ ë®ì–´ì“°ê¸°"
    ),
):
    """
    íŒŒì¼ì—ì„œ ì „ë¬¸ìš©ì–´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        paper-translator terms import terms.json
        paper-translator terms import terms.json --overwrite
    """
    try:
        # íŒŒì¼ í˜•ì‹ ê°ì§€
        suffix = file.suffix.lower()

        if suffix == ".json":
            with open(file, "r", encoding="utf-8") as f:
                terms = json.load(f)
        elif suffix == ".csv":
            import csv
            with open(file, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                terms = list(reader)
        else:
            print_error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {suffix}")
            raise typer.Exit(1)

        # ìš©ì–´ ì¶”ê°€
        added = 0
        skipped = 0
        updated = 0

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console,
        ) as progress:
            task = progress.add_task("[cyan]ê°€ì ¸ì˜¤ëŠ” ì¤‘...", total=len(terms))

            for term in terms:
                progress.update(task, advance=1)

                term_data = {
                    "source_text": term.get("source_text", ""),
                    "target_text": term.get("target_text", ""),
                    "domain": term.get("domain", "General"),
                    "description": term.get("description", ""),
                    "usage_count": int(term.get("usage_count", 0)),
                }

                if not term_data["source_text"] or not term_data["target_text"]:
                    skipped += 1
                    continue

                # ê¸°ì¡´ ìš©ì–´ í™•ì¸
                existing = TerminologyRepository.search(term_data["source_text"])
                if existing:
                    if overwrite:
                        TerminologyRepository.update(existing[0]["id"], term_data)
                        updated += 1
                    else:
                        skipped += 1
                else:
                    TerminologyRepository.create(term_data)
                    added += 1

        print_success(f"ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ!")
        console.print(f"  ì¶”ê°€: {added}ê°œ")
        console.print(f"  ìˆ˜ì •: {updated}ê°œ")
        console.print(f"  ê±´ë„ˆëœ€: {skipped}ê°œ")

    except Exception as e:
        print_error(f"ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        raise typer.Exit(1)


# === sync ëª…ë ¹ì–´ ===

def create_sync_items_table(items: list[SyncItem]) -> Table:
    """ë™ê¸°í™” í•­ëª© í…Œì´ë¸” ìƒì„±"""
    table = Table(title="ë™ê¸°í™” í•­ëª©", show_header=True, header_style="bold cyan")
    table.add_column("ì•¡ì…˜", style="yellow", width=15)
    table.add_column("ì„¤ëª…", style="white")
    table.add_column("í™•ì‹ ë„", justify="right", width=10)

    action_icons = {
        SyncAction.UPDATE_TERM: "[blue]ğŸ“ ì—…ë°ì´íŠ¸[/blue]",
        SyncAction.ADD_TERM: "[green]â• ì¶”ê°€[/green]",
        SyncAction.LOG_CHANGE: "[dim]ğŸ“‹ ë¡œê·¸[/dim]",
        SyncAction.UPDATE_HASH: "[cyan]ğŸ”„ í•´ì‹œ[/cyan]",
        SyncAction.SKIP: "[dim]â­ï¸ ê±´ë„ˆëœ€[/dim]",
    }

    for item in items:
        action_text = action_icons.get(item.action, item.action.value)
        confidence = item.data.get("confidence")
        confidence_str = f"{confidence:.0%}" if confidence else "-"

        table.add_row(action_text, item.description, confidence_str)

    return table


def create_sync_result_table(result: SyncResult) -> Table:
    """ë™ê¸°í™” ê²°ê³¼ í…Œì´ë¸” ìƒì„±"""
    table = Table(title="ë™ê¸°í™” ê²°ê³¼", show_header=True, header_style="bold magenta")
    table.add_column("í•­ëª©", style="cyan")
    table.add_column("ê°’", style="green")

    table.add_row("íŒŒì¼", result.file_path)
    table.add_row("ì„±ê³µ ì—¬ë¶€", "[green]âœ“[/green]" if result.success else "[red]âœ—[/red]")
    table.add_row("ìš©ì–´ ì—…ë°ì´íŠ¸", str(result.terms_updated))
    table.add_row("ìš©ì–´ ì¶”ê°€", str(result.terms_added))
    table.add_row("ë³€ê²½ ë¡œê·¸", str(result.changes_logged))
    table.add_row("í•´ì‹œ ì—…ë°ì´íŠ¸", "[green]âœ“[/green]" if result.hash_updated else "[dim]-[/dim]")

    if result.error:
        table.add_row("ë¹„ê³ ", f"[dim]{result.error}[/dim]")

    return table


@app.command("sync", help="ë²ˆì—­ ê²°ê³¼ ë™ê¸°í™”")
def sync(
    file: Optional[Path] = typer.Option(
        None, "--file", "-f",
        help="ë™ê¸°í™”í•  ë§ˆí¬ë‹¤ìš´ íŒŒì¼",
        exists=True,
        file_okay=True,
    ),
    all_files: bool = typer.Option(
        False, "--all", "-a",
        help="ëª¨ë“  ë³€ê²½ íŒŒì¼ ë™ê¸°í™”"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run",
        help="ì‹¤ì œ ë³€ê²½ ì—†ì´ ë³€ê²½ ì‚¬í•­ë§Œ í™•ì¸"
    ),
    auto: bool = typer.Option(
        False, "--auto",
        help="í™•ì¸ ì—†ì´ ìë™ ë™ê¸°í™”"
    ),
    output_dir: Path = typer.Option(
        Path("./translations"), "--output-dir", "-o",
        help="ë²ˆì—­ íŒŒì¼ ë””ë ‰í† ë¦¬ (--all ì˜µì…˜ìš©)"
    ),
    use_llm: bool = typer.Option(
        True, "--llm/--no-llm",
        help="LLM ë¶„ì„ ì‚¬ìš© ì—¬ë¶€"
    ),
    min_confidence: float = typer.Option(
        0.7, "--min-confidence", "-c",
        help="ìµœì†Œ í™•ì‹ ë„ (0.0 ~ 1.0)"
    ),
    verbose: bool = typer.Option(
        False, "--verbose", "-v",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥"
    ),
):
    """
    ë²ˆì—­ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ë³€ê²½ ì‚¬í•­ì„ DBì— ë™ê¸°í™”í•©ë‹ˆë‹¤.

    ì‚¬ìš©ìê°€ ë²ˆì—­ ê²°ê³¼(ë§ˆí¬ë‹¤ìš´ íŒŒì¼)ë¥¼ ìˆ˜ì •í•˜ë©´,
    ë³€ê²½ëœ ìš©ì–´ë¥¼ ìë™ìœ¼ë¡œ DBì— ë°˜ì˜í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        # ë‹¨ì¼ íŒŒì¼ ë™ê¸°í™” (í™•ì¸ í•„ìš”)
        paper-translator sync --file output/translated.md

        # ë³€ê²½ ì‚¬í•­ë§Œ ë¯¸ë¦¬ë³´ê¸° (dry-run)
        paper-translator sync --file output/translated.md --dry-run

        # ìë™ ë™ê¸°í™” (í™•ì¸ ì—†ì´)
        paper-translator sync --file output/translated.md --auto

        # ëª¨ë“  ë³€ê²½ íŒŒì¼ ë™ê¸°í™”
        paper-translator sync --all --output-dir ./translations

        # LLM ë¶„ì„ ì—†ì´ íœ´ë¦¬ìŠ¤í‹±ë§Œ ì‚¬ìš©
        paper-translator sync --file output/translated.md --no-llm
    """
    print_header("ë²ˆì—­ ê²°ê³¼ ë™ê¸°í™”")

    # ì…ë ¥ ê²€ì¦
    if not file and not all_files:
        print_error("--file ë˜ëŠ” --all ì˜µì…˜ ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        raise typer.Exit(1)

    # ë™ê¸°í™”í•  íŒŒì¼ ëª©ë¡ ê²°ì •
    files_to_sync: list[str] = []

    if file:
        files_to_sync = [str(file)]
        print_info(f"ëŒ€ìƒ íŒŒì¼: {file}")
    elif all_files:
        print_info(f"ë³€ê²½ëœ íŒŒì¼ ê²€ìƒ‰ ì¤‘: {output_dir}")
        files_to_sync = get_changed_files(str(output_dir))

        if not files_to_sync:
            print_success("ë³€ê²½ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        print_info(f"ë³€ê²½ëœ íŒŒì¼ {len(files_to_sync)}ê°œ ë°œê²¬")
        for f in files_to_sync:
            console.print(f"  â€¢ {f}")

    console.print()

    # ì„¤ì • ì¶œë ¥
    if verbose:
        console.print(f"[dim]LLM ë¶„ì„: {use_llm}[/dim]")
        console.print(f"[dim]ìµœì†Œ í™•ì‹ ë„: {min_confidence:.0%}[/dim]")
        console.print(f"[dim]ìë™ ë™ê¸°í™”: {auto}[/dim]")
        console.print(f"[dim]Dry run: {dry_run}[/dim]")
        console.print()

    # ì‚¬ìš©ì í™•ì¸ ì½œë°±
    def confirm_sync(items: list[SyncItem]) -> bool:
        """ì‚¬ìš©ì í™•ì¸ ì½œë°±"""
        # ë™ê¸°í™” í•­ëª© í…Œì´ë¸” ì¶œë ¥
        console.print(create_sync_items_table(items))
        console.print()

        # ìš”ì•½
        update_count = sum(1 for i in items if i.action == SyncAction.UPDATE_TERM)
        add_count = sum(1 for i in items if i.action == SyncAction.ADD_TERM)
        skip_count = sum(1 for i in items if i.action == SyncAction.SKIP)

        console.print(f"[bold]ìš”ì•½:[/bold] ì—…ë°ì´íŠ¸ {update_count}ê±´, ì¶”ê°€ {add_count}ê±´, ê±´ë„ˆëœ€ {skip_count}ê±´")
        console.print()

        return typer.confirm("ë™ê¸°í™”ë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")

    # SyncManager ìƒì„±
    manager = SyncManager(
        auto_sync=auto,
        confirm_callback=None if dry_run else confirm_sync,
        min_confidence=min_confidence,
        use_llm_analysis=use_llm
    )

    # ë™ê¸°í™” ì‹¤í–‰
    try:
        results: list[SyncResult] = []

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console,
        ) as progress:
            task = progress.add_task("[cyan]ë™ê¸°í™” ì¤‘...", total=len(files_to_sync))

            for file_path in files_to_sync:
                progress.update(task, description=f"[cyan]{Path(file_path).name}...")

                result = manager.sync_file(file_path, dry_run=dry_run)
                results.append(result)

                progress.update(task, advance=1)

        console.print()

        # ê²°ê³¼ ì¶œë ¥
        if dry_run:
            print_warning("Dry run ëª¨ë“œ: ì‹¤ì œ ë³€ê²½ì€ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            console.print()

            for result in results:
                if result.items:
                    console.print(f"[bold]{result.file_path}[/bold]")
                    console.print(create_sync_items_table(result.items))
                    console.print()
                else:
                    console.print(f"[dim]{result.file_path}: {result.error or 'ë³€ê²½ ì‚¬í•­ ì—†ìŒ'}[/dim]")
        else:
            # ì „ì²´ ê²°ê³¼ ìš”ì•½
            summary = manager.get_sync_summary(results)

            console.print(Panel(
                f"[bold]íŒŒì¼:[/bold] {summary['total_files']}ê°œ "
                f"([green]ì„±ê³µ {summary['success']}[/green], "
                f"[red]ì‹¤íŒ¨ {summary['failed']}[/red])\n"
                f"[bold]ìš©ì–´ ì—…ë°ì´íŠ¸:[/bold] {summary['terms_updated']}ê±´\n"
                f"[bold]ìš©ì–´ ì¶”ê°€:[/bold] {summary['terms_added']}ê±´\n"
                f"[bold]ë³€ê²½ ë¡œê·¸:[/bold] {summary['changes_logged']}ê±´",
                title="ë™ê¸°í™” ì™„ë£Œ",
                expand=False
            ))

            # ê°œë³„ ê²°ê³¼ (verbose ëª¨ë“œ)
            if verbose:
                console.print()
                for result in results:
                    console.print(create_sync_result_table(result))
                    console.print()

            # ì„±ê³µ/ì‹¤íŒ¨ ë©”ì‹œì§€
            if summary['failed'] == 0:
                print_success("ëª¨ë“  íŒŒì¼ ë™ê¸°í™” ì™„ë£Œ!")
            else:
                print_warning(f"{summary['failed']}ê°œ íŒŒì¼ ë™ê¸°í™” ì‹¤íŒ¨")

                for result in results:
                    if not result.success:
                        print_error(f"  {result.file_path}: {result.error}")

    except KeyboardInterrupt:
        print_warning("\në™ê¸°í™”ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        raise typer.Exit(130)
    except Exception as e:
        print_error(f"ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        if verbose:
            console.print_exception()
        raise typer.Exit(1)


# === ë²„ì „ ë° ì •ë³´ ===

@app.command("version", help="ë²„ì „ ì •ë³´")
def version():
    """ë²„ì „ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    from src import __version__
    console.print(f"[bold]Paper Translator[/bold] v{__version__}")
    console.print("ArXiv ë…¼ë¬¸ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ë„êµ¬")


@app.command("info", help="ì‹œìŠ¤í…œ ì •ë³´")
def info():
    """ì‹œìŠ¤í…œ ë° ì„¤ì • ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    from src.utils import settings

    print_header("ì‹œìŠ¤í…œ ì •ë³´")

    table = Table(show_header=True, header_style="bold cyan")
    table.add_column("í•­ëª©", style="cyan")
    table.add_column("ê°’", style="green")

    table.add_row("OpenAI ëª¨ë¸", settings.openai_model)
    table.add_row("ìµœëŒ€ ì²­í¬ í† í°", str(settings.max_chunk_tokens))
    table.add_row("ì˜¤ë²„ë© í† í°", str(settings.overlap_tokens))
    table.add_row("ì²­í‚¹ ì „ëµ", settings.chunking_strategy)
    table.add_row("ë²ˆì—­ Temperature", str(settings.translation_temperature))
    table.add_row("ì¶œë ¥ ë””ë ‰í† ë¦¬", settings.output_directory)
    table.add_row("íŒŒì¼ëª… í˜•ì‹", settings.filename_format)

    console.print(table)


# === discover ëª…ë ¹ì–´ ===

def create_arxiv_table(papers: list[ArxivPaper], start_idx: int = 0) -> Table:
    """ArXiv ë…¼ë¬¸ í…Œì´ë¸” ìƒì„±"""
    table = Table(title=f"ArXiv ë…¼ë¬¸ ({len(papers)}ê°œ)", show_header=True, header_style="bold cyan")
    table.add_column("#", style="dim", width=3)
    table.add_column("ArXiv ID", style="cyan", width=15)
    table.add_column("ì œëª©", style="white", max_width=45)
    table.add_column("ì €ì", style="dim", max_width=20)
    table.add_column("ì¹´í…Œê³ ë¦¬", style="yellow", width=8)
    table.add_column("ë‚ ì§œ", style="green", width=10)

    for idx, paper in enumerate(papers, start_idx + 1):
        authors = ", ".join(paper.authors[:2])
        if len(paper.authors) > 2:
            authors += f" ì™¸ {len(paper.authors) - 2}ëª…"

        table.add_row(
            str(idx),
            paper.arxiv_id,
            paper.title[:45] + "..." if len(paper.title) > 45 else paper.title,
            authors[:20] + "..." if len(authors) > 20 else authors,
            paper.primary_category,
            paper.published.strftime("%Y-%m-%d"),
        )

    return table


def paginate_results(papers: list, page: int, per_page: int) -> tuple[list, int, int]:
    """
    ê²°ê³¼ë¥¼ í˜ì´ì§€ë„¤ì´ì…˜í•©ë‹ˆë‹¤.

    Returns:
        (í˜„ì¬ í˜ì´ì§€ ë…¼ë¬¸ ëª©ë¡, ì´ í˜ì´ì§€ ìˆ˜, ì‹œì‘ ì¸ë±ìŠ¤)
    """
    total = len(papers)
    total_pages = (total + per_page - 1) // per_page  # ceiling division

    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page

    return papers[start_idx:end_idx], total_pages, start_idx


def create_semantic_scholar_table(papers: list[SemanticScholarPaper], start_idx: int = 0) -> Table:
    """Semantic Scholar ë…¼ë¬¸ í…Œì´ë¸” ìƒì„±"""
    table = Table(title=f"Semantic Scholar ë…¼ë¬¸ ({len(papers)}ê°œ)", show_header=True, header_style="bold cyan")
    table.add_column("#", style="dim", width=3)
    table.add_column("ArXiv ID", style="cyan", width=15)
    table.add_column("ì œëª©", style="white", max_width=40)
    table.add_column("ì €ì", style="dim", max_width=18)
    table.add_column("ì¸ìš©ìˆ˜", style="yellow", justify="right", width=8)
    table.add_column("ì˜í–¥ë ¥", style="green", justify="right", width=8)
    table.add_column("ì—°ë„", style="cyan", width=6)

    for idx, paper in enumerate(papers, start_idx + 1):
        authors = ", ".join(paper.authors[:2])
        if len(paper.authors) > 2:
            authors += f" ì™¸ {len(paper.authors) - 2}ëª…"

        # ArXiv ID í‘œì‹œ (ì—†ìœ¼ë©´ "-")
        arxiv_display = paper.arxiv_id if paper.arxiv_id else "-"

        table.add_row(
            str(idx),
            arxiv_display,
            paper.title[:40] + "..." if len(paper.title) > 40 else paper.title,
            authors[:18] + "..." if len(authors) > 18 else authors,
            f"{paper.citation_count:,}",
            f"{paper.influential_citation_count:,}",
            str(paper.year) if paper.year else "-",
        )

    return table


@app.command("discover", help="ë…¼ë¬¸ ê²€ìƒ‰ ë° ë°œê²¬")
def discover(
    source: str = typer.Option(
        "arxiv", "--source", "-s",
        help="ê²€ìƒ‰ ì†ŒìŠ¤ (arxiv, semantic-scholar)"
    ),
    query: Optional[str] = typer.Option(
        None, "--query", "-q",
        help="ê²€ìƒ‰ì–´"
    ),
    domain: str = typer.Option(
        "General", "--domain", "-d",
        help="ë„ë©”ì¸ (NLP, CV, ML, RL, Speech, General)"
    ),
    page: int = typer.Option(
        1, "--page", "-p",
        help="í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)"
    ),
    per_page: int = typer.Option(
        10, "--per-page",
        help="í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 10)"
    ),
    max_results: int = typer.Option(
        100, "--max-results", "-n",
        help="ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ì „ì²´)"
    ),
    min_citations: int = typer.Option(
        0, "--min-citations", "-c",
        help="ìµœì†Œ ì¸ìš©ìˆ˜ (Semantic Scholar ì „ìš©)"
    ),
    year_from: Optional[int] = typer.Option(
        None, "--year-from", "-y",
        help="ì‹œì‘ ì—°ë„ í•„í„°"
    ),
    trending: bool = typer.Option(
        False, "--trending", "-t",
        help="ì¸ê¸°/ìµœì‹  ë…¼ë¬¸ ì¡°íšŒ"
    ),
    highly_cited: bool = typer.Option(
        False, "--highly-cited", "-h",
        help="ê³ ì¸ìš© ë…¼ë¬¸ ì¡°íšŒ (Semantic Scholar ì „ìš©)"
    ),
    json_output: bool = typer.Option(
        False, "--json",
        help="JSON í˜•ì‹ ì¶œë ¥"
    ),
    verbose: bool = typer.Option(
        False, "--verbose", "-v",
        help="ìƒì„¸ ì •ë³´ ì¶œë ¥"
    ),
):
    """
    ArXiv ë˜ëŠ” Semantic Scholarì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:

        # ArXivì—ì„œ transformer ê²€ìƒ‰
        paper-translator discover --source arxiv --query "transformer" --domain NLP

        # ArXiv ìµœì‹  íŠ¸ë Œë”© ë…¼ë¬¸
        paper-translator discover --source arxiv --domain NLP --trending

        # Semantic Scholarì—ì„œ ê³ ì¸ìš© ë…¼ë¬¸ ê²€ìƒ‰
        paper-translator discover --source semantic-scholar --domain ML --highly-cited

        # Semantic Scholarì—ì„œ ì¸ìš©ìˆ˜ 100 ì´ìƒ í•„í„°
        paper-translator discover --source semantic-scholar --query "BERT" --min-citations 100

        # í˜ì´ì§€ë„¤ì´ì…˜ (2í˜ì´ì§€ ì¡°íšŒ)
        paper-translator discover --source arxiv --domain NLP --trending --page 2
    """
    print_header("ë…¼ë¬¸ ê²€ìƒ‰")

    source = source.lower()
    valid_sources = ["arxiv", "semantic-scholar", "s2"]

    if source not in valid_sources:
        print_error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì†ŒìŠ¤: {source}")
        print_info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì†ŒìŠ¤: {', '.join(valid_sources)}")
        raise typer.Exit(1)

    # ê²€ìƒ‰ì–´ ë˜ëŠ” ì˜µì…˜ í™•ì¸
    if not query and not trending and not highly_cited:
        print_error("--query, --trending, ë˜ëŠ” --highly-cited ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        raise typer.Exit(1)

    # í˜ì´ì§€ ìœ íš¨ì„± ê²€ì‚¬
    if page < 1:
        print_error("í˜ì´ì§€ ë²ˆí˜¸ëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        raise typer.Exit(1)
    if per_page < 1 or per_page > 100:
        print_error("í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜ëŠ” 1~100 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        raise typer.Exit(1)

    console.print(f"ì†ŒìŠ¤: [cyan]{source}[/cyan]")
    console.print(f"ë„ë©”ì¸: [cyan]{domain}[/cyan]")
    if query:
        console.print(f"ê²€ìƒ‰ì–´: [cyan]{query}[/cyan]")
    console.print(f"í˜ì´ì§€: [cyan]{page}[/cyan] (í˜ì´ì§€ë‹¹ {per_page}ê°œ)")
    console.print()

    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
        ) as progress:
            task = progress.add_task("[cyan]ê²€ìƒ‰ ì¤‘...", total=None)

            # ArXiv ê²€ìƒ‰
            if source == "arxiv":
                collector = ArxivCollector(max_results=max_results)

                if trending:
                    papers = collector.get_trending(domain=domain, max_results=max_results)
                elif query:
                    papers = collector.search_by_domain(
                        query=query,
                        domain=domain,
                        max_results=max_results,
                    )
                else:
                    papers = collector.get_recent(domain=domain, max_results=max_results)

                progress.update(task, completed=True)

                if not papers:
                    print_warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return

                # ì „ì²´ ê²°ê³¼ ì €ì¥ (í˜ì´ì§€ë„¤ì´ì…˜ìš©)
                all_papers = papers
                total_count = len(all_papers)

                # í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
                papers, total_pages, start_idx = paginate_results(all_papers, page, per_page)

                if not papers:
                    print_warning(f"í˜ì´ì§€ {page}ì— ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ {total_pages}í˜ì´ì§€)")
                    return

                if json_output:
                    console.print_json(data=[p.to_dict() for p in papers])
                    return

                console.print()
                console.print(create_arxiv_table(papers, start_idx))

                # ìƒì„¸ ì •ë³´ ì¶œë ¥
                if verbose:
                    console.print()
                    for idx, paper in enumerate(papers, start_idx + 1):
                        console.print(Panel(
                            f"[bold]ì œëª©:[/bold] {paper.title}\n"
                            f"[bold]ì €ì:[/bold] {', '.join(paper.authors)}\n"
                            f"[bold]ArXiv ID:[/bold] {paper.arxiv_id}\n"
                            f"[bold]ì¹´í…Œê³ ë¦¬:[/bold] {', '.join(paper.categories)}\n"
                            f"[bold]ê²Œì‹œì¼:[/bold] {paper.published.strftime('%Y-%m-%d')}\n"
                            f"[bold]PDF:[/bold] {paper.pdf_url}\n\n"
                            f"[bold]ì´ˆë¡:[/bold]\n{paper.abstract[:500]}{'...' if len(paper.abstract) > 500 else ''}",
                            title=f"[{idx}] ìƒì„¸ ì •ë³´",
                            expand=False,
                        ))

                # í˜ì´ì§€ ì •ë³´ ì¶œë ¥
                console.print()
                console.print(f"[dim]í˜ì´ì§€ {page}/{total_pages} (ì´ {total_count}ê°œ ê²°ê³¼)[/dim]")

                if page < total_pages:
                    next_cmd = f"paper-translator discover --source arxiv"
                    if query:
                        next_cmd += f' --query "{query}"'
                    next_cmd += f" --domain {domain} --page {page + 1}"
                    if trending:
                        next_cmd += " --trending"
                    console.print(f"[dim]ë‹¤ìŒ í˜ì´ì§€: {next_cmd}[/dim]")

            # Semantic Scholar ê²€ìƒ‰
            else:  # semantic-scholar or s2
                collector = SemanticScholarCollector(max_results=max_results)

                if highly_cited:
                    papers = collector.get_highly_cited(
                        domain=domain,
                        max_results=max_results,
                        year_from=year_from,
                        min_citations=max(min_citations, 100),  # ìµœì†Œ 100
                    )
                elif trending:
                    papers = collector.get_influential(
                        domain=domain,
                        max_results=max_results,
                        year_from=year_from,
                    )
                elif query:
                    papers = collector.search_by_domain(
                        query=query,
                        domain=domain,
                        max_results=max_results,
                        year_from=year_from,
                        min_citations=min_citations,
                    )
                else:
                    papers = collector.search_by_domain(
                        query=domain,
                        domain=domain,
                        max_results=max_results,
                    )

                progress.update(task, completed=True)

                if not papers:
                    print_warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return

                # ì „ì²´ ê²°ê³¼ ì €ì¥ (í˜ì´ì§€ë„¤ì´ì…˜ìš©)
                all_papers = papers
                total_count = len(all_papers)

                # í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
                papers, total_pages, start_idx = paginate_results(all_papers, page, per_page)

                if not papers:
                    print_warning(f"í˜ì´ì§€ {page}ì— ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ {total_pages}í˜ì´ì§€)")
                    return

                if json_output:
                    console.print_json(data=[p.to_dict() for p in papers])
                    return

                console.print()
                console.print(create_semantic_scholar_table(papers, start_idx))

                # ìƒì„¸ ì •ë³´ ì¶œë ¥
                if verbose:
                    console.print()
                    for idx, paper in enumerate(papers, start_idx + 1):
                        arxiv_info = f"\n[bold]ArXiv ID:[/bold] {paper.arxiv_id}" if paper.arxiv_id else ""
                        pdf_info = f"\n[bold]PDF:[/bold] {paper.pdf_url}" if paper.pdf_url else ""

                        console.print(Panel(
                            f"[bold]ì œëª©:[/bold] {paper.title}\n"
                            f"[bold]ì €ì:[/bold] {', '.join(paper.authors)}\n"
                            f"[bold]ì—°ë„:[/bold] {paper.year or 'N/A'}\n"
                            f"[bold]ì¸ìš©ìˆ˜:[/bold] {paper.citation_count:,}\n"
                            f"[bold]ì˜í–¥ë ¥ ì¸ìš©ìˆ˜:[/bold] {paper.influential_citation_count:,}\n"
                            f"[bold]ë¶„ì•¼:[/bold] {', '.join(paper.fields_of_study) if paper.fields_of_study else 'N/A'}"
                            f"{arxiv_info}{pdf_info}\n\n"
                            f"[bold]ì´ˆë¡:[/bold]\n{paper.abstract[:500] if paper.abstract else 'N/A'}{'...' if paper.abstract and len(paper.abstract) > 500 else ''}",
                            title=f"[{idx}] ìƒì„¸ ì •ë³´",
                            expand=False,
                        ))

                # í˜ì´ì§€ ì •ë³´ ì¶œë ¥
                console.print()
                console.print(f"[dim]í˜ì´ì§€ {page}/{total_pages} (ì´ {total_count}ê°œ ê²°ê³¼)[/dim]")

                if page < total_pages:
                    next_cmd = f"paper-translator discover --source semantic-scholar"
                    if query:
                        next_cmd += f' --query "{query}"'
                    next_cmd += f" --domain {domain} --page {page + 1}"
                    if highly_cited:
                        next_cmd += " --highly-cited"
                    if trending:
                        next_cmd += " --trending"
                    console.print(f"[dim]ë‹¤ìŒ í˜ì´ì§€: {next_cmd}[/dim]")

        console.print()
        print_success(f"{len(papers)}ê°œ ë…¼ë¬¸ í‘œì‹œ (í˜„ì¬ í˜ì´ì§€)")

        # ë²ˆì—­ ì œì•ˆ
        console.print()
        console.print("[dim]ë…¼ë¬¸ ë²ˆì—­í•˜ê¸°:[/dim]")
        if source == "arxiv" and papers:
            sample = papers[0]
            console.print(f"  [dim]paper-translator translate --arxiv-id {sample.arxiv_id} --domain {domain}[/dim]")
        elif papers and papers[0].arxiv_id:
            sample = papers[0]
            console.print(f"  [dim]paper-translator translate --arxiv-id {sample.arxiv_id} --domain {domain}[/dim]")

    except KeyboardInterrupt:
        print_warning("\nê²€ìƒ‰ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        raise typer.Exit(130)
    except RateLimitError as e:
        print_error(f"API ìš”ì²­ ì œí•œ ì´ˆê³¼")
        console.print()
        console.print("[yellow]í•´ê²° ë°©ë²•:[/yellow]")
        console.print("  1. ëª‡ ë¶„ í›„ ë‹¤ì‹œ ì‹œë„")
        console.print("  2. Semantic Scholar API í‚¤ ë°œê¸‰ (ë¬´ë£Œ):")
        console.print("     [dim]https://www.semanticscholar.org/product/api#api-key-form[/dim]")
        console.print("  3. í™˜ê²½ë³€ìˆ˜ë¡œ API í‚¤ ì„¤ì •:")
        console.print("     [dim]export SEMANTIC_SCHOLAR_API_KEY=your_key[/dim]")
        console.print()
        console.print("[dim]ë˜ëŠ” ArXivë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”:[/dim]")
        console.print(f"  [dim]paper-translator discover --source arxiv --domain {domain} --trending[/dim]")
        raise typer.Exit(1)
    except Exception as e:
        print_error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        if verbose:
            console.print_exception()
        raise typer.Exit(1)


# === ë©”ì¸ ì—”íŠ¸ë¦¬ ===

def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    app()


if __name__ == "__main__":
    main()
