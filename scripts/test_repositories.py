"""
Repository í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê° Repositoryì˜ CRUD ê¸°ëŠ¥ ê²€ì¦
"""
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.db import (
    TerminologyRepository,
    TranslationRepository,
    TranslationHistoryRepository,
    TermChangeRepository,
)


def test_terminology_repository():
    """TerminologyRepository í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“š TerminologyRepository í…ŒìŠ¤íŠ¸")
    print("-" * 50)

    # 1. get_all í…ŒìŠ¤íŠ¸
    terms = TerminologyRepository.get_all(limit=5)
    print(f"âœ… get_all: {len(terms)}ê°œ ìš©ì–´ ì¡°íšŒ")

    # 2. get_all with domain í…ŒìŠ¤íŠ¸
    nlp_terms = TerminologyRepository.get_all(domain="NLP", limit=5)
    print(f"âœ… get_all(domain='NLP'): {len(nlp_terms)}ê°œ ìš©ì–´ ì¡°íšŒ")

    # 3. get_by_source í…ŒìŠ¤íŠ¸
    term = TerminologyRepository.get_by_source("Transformer", domain="NLP")
    if term:
        print(f"âœ… get_by_source('Transformer'): {term['target_text']}")
    else:
        print("âš ï¸ get_by_source('Transformer'): ì—†ìŒ")

    # 4. search í…ŒìŠ¤íŠ¸
    search_results = TerminologyRepository.search("attention", limit=3)
    print(f"âœ… search('attention'): {len(search_results)}ê°œ ê²°ê³¼")

    # 5. get_matching_terms í…ŒìŠ¤íŠ¸
    sample_text = "The Transformer model uses self-attention mechanism for better performance."
    matching = TerminologyRepository.get_matching_terms(sample_text, limit=5)
    print(f"âœ… get_matching_terms: {len(matching)}ê°œ ë§¤ì¹­ ìš©ì–´")
    for m in matching[:3]:
        print(f"   - {m['source_text']} â†’ {m['target_text']}")

    return True


def test_translation_repository():
    """TranslationRepository í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“„ TranslationRepository í…ŒìŠ¤íŠ¸")
    print("-" * 50)

    # 1. create í…ŒìŠ¤íŠ¸
    translation = TranslationRepository.create(
        paper_title="[TEST] Attention Is All You Need",
        output_path="./translations/test_attention.md",
        paper_url="https://arxiv.org/pdf/1706.03762",
        arxiv_id="1706.03762_test",
        domain="NLP",
        total_chunks=10
    )

    if translation:
        print(f"âœ… create: ID={translation['id'][:8]}...")
        translation_id = translation["id"]

        # 2. get_by_id í…ŒìŠ¤íŠ¸
        fetched = TranslationRepository.get_by_id(translation_id)
        print(f"âœ… get_by_id: {fetched['paper_title'][:30]}...")

        # 3. update_status í…ŒìŠ¤íŠ¸
        updated = TranslationRepository.update_status(translation_id, "completed")
        print(f"âœ… update_status: {updated['status']}")

        # 4. update_hashes í…ŒìŠ¤íŠ¸
        TranslationRepository.update_hashes(translation_id, "abc123hash", "abc123hash")
        print("âœ… update_hashes: ì„±ê³µ")

        # 5. delete í…ŒìŠ¤íŠ¸
        deleted = TranslationRepository.delete(translation_id)
        print(f"âœ… delete: {deleted}")

        return True
    else:
        print("âŒ create ì‹¤íŒ¨")
        return False


def test_translation_history_repository():
    """TranslationHistoryRepository í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“ TranslationHistoryRepository í…ŒìŠ¤íŠ¸")
    print("-" * 50)

    # ë¨¼ì € ë²ˆì—­ ê¸°ë¡ ìƒì„±
    translation = TranslationRepository.create(
        paper_title="[TEST] History Test Paper",
        output_path="./translations/test_history.md"
    )

    if not translation:
        print("âŒ ë²ˆì—­ ê¸°ë¡ ìƒì„± ì‹¤íŒ¨")
        return False

    translation_id = translation["id"]

    try:
        # 1. create í…ŒìŠ¤íŠ¸
        history1 = TranslationHistoryRepository.create(
            translation_id=translation_id,
            chunk_index=0,
            original_text="This is the abstract.",
            translated_text="ì´ê²ƒì€ ì´ˆë¡ì…ë‹ˆë‹¤.",
            section_title="Abstract",
            terms_applied=[{"source": "abstract", "target": "ì´ˆë¡"}],
            tokens_used=50
        )
        print(f"âœ… create: chunk_index={history1['chunk_index']}")

        # 2. bulk_create í…ŒìŠ¤íŠ¸
        chunks = [
            {
                "translation_id": translation_id,
                "chunk_index": 1,
                "original_text": "Introduction text.",
                "translated_text": "ì„œë¡  í…ìŠ¤íŠ¸.",
                "section_title": "Introduction"
            },
            {
                "translation_id": translation_id,
                "chunk_index": 2,
                "original_text": "Method text.",
                "translated_text": "ë°©ë²• í…ìŠ¤íŠ¸.",
                "section_title": "Method"
            }
        ]
        bulk_result = TranslationHistoryRepository.bulk_create(chunks)
        print(f"âœ… bulk_create: {len(bulk_result)}ê°œ ìƒì„±")

        # 3. get_by_translation í…ŒìŠ¤íŠ¸
        all_chunks = TranslationHistoryRepository.get_by_translation(translation_id)
        print(f"âœ… get_by_translation: {len(all_chunks)}ê°œ ì²­í¬")

        # 4. get_chunk í…ŒìŠ¤íŠ¸
        chunk = TranslationHistoryRepository.get_chunk(translation_id, 0)
        print(f"âœ… get_chunk(0): {chunk['section_title']}")

        return True

    finally:
        # ì •ë¦¬: ë²ˆì—­ ê¸°ë¡ ì‚­ì œ (cascadeë¡œ historyë„ ì‚­ì œë¨)
        TranslationRepository.delete(translation_id)
        print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")


def test_term_change_repository():
    """TermChangeRepository í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“‹ TermChangeRepository í…ŒìŠ¤íŠ¸")
    print("-" * 50)

    # 1. log_add í…ŒìŠ¤íŠ¸
    add_log = TermChangeRepository.log_add(
        source_text="test_term",
        new_target_text="í…ŒìŠ¤íŠ¸ ìš©ì–´",
        detected_from="manual"
    )
    print(f"âœ… log_add: {add_log['change_type']}")

    # 2. log_update í…ŒìŠ¤íŠ¸
    update_log = TermChangeRepository.log_update(
        source_text="test_term",
        old_target_text="í…ŒìŠ¤íŠ¸ ìš©ì–´",
        new_target_text="í…ŒìŠ¤íŠ¸ ìš©ì–´ ìˆ˜ì •",
        detected_from="markdown_sync"
    )
    print(f"âœ… log_update: {update_log['change_type']}")

    # 3. log_delete í…ŒìŠ¤íŠ¸
    delete_log = TermChangeRepository.log_delete(
        source_text="test_term",
        old_target_text="í…ŒìŠ¤íŠ¸ ìš©ì–´ ìˆ˜ì •",
        detected_from="manual"
    )
    print(f"âœ… log_delete: {delete_log['change_type']}")

    # 4. get_all í…ŒìŠ¤íŠ¸
    all_logs = TermChangeRepository.get_all(limit=5)
    print(f"âœ… get_all: {len(all_logs)}ê°œ ë¡œê·¸")

    return True


def main():
    print("ğŸ§ª Repository í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    results = {
        "TerminologyRepository": test_terminology_repository(),
        "TranslationRepository": test_translation_repository(),
        "TranslationHistoryRepository": test_translation_history_repository(),
        "TermChangeRepository": test_term_change_repository(),
    }

    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    all_passed = True
    for repo, passed in results.items():
        status = "âœ… í†µê³¼" if passed else "âŒ ì‹¤íŒ¨"
        print(f"  {repo}: {status}")
        if not passed:
            all_passed = False

    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ ëª¨ë“  Repository í…ŒìŠ¤íŠ¸ í†µê³¼!")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())
